{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN final assignment - eye.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfMK5FEhUGde"
      },
      "source": [
        "## Download the images\n",
        "\n",
        "\n",
        "We can use **GoogleDriveDownloader** form **google_drive_downloader** library in Python to download the shared files from the shared Google drive link: https://drive.google.com/file/d/1f7uslI-ZHidriQFZR966_aILjlkgDN76/view?usp=sharing\n",
        "\n",
        "The file id in the above link is: **1f7uslI-ZHidriQFZR966_aILjlkgDN76**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_1BysB4Re7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda11145-4168-4e21-8b56-05cde447217e"
      },
      "source": [
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "gdd.download_file_from_google_drive(file_id='1f7uslI-ZHidriQFZR966_aILjlkgDN76',\n",
        "                                    dest_path='content/eye_gender_data.zip',\n",
        "                                    unzip=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1f7uslI-ZHidriQFZR966_aILjlkgDN76 into content/eye_gender_data.zip... Done.\n",
            "Unzipping...Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM_FDQgXbh_-"
      },
      "source": [
        "We have all the files from the shared Google drive link downloaded in the colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsIqjb7Ebs3B"
      },
      "source": [
        "## Loading Libraries\n",
        "All Python capabilities are not loaded to our working environment by default (even they are already installed in your system). So, we import each and every library that we want to use.\n",
        "\n",
        "We chose alias names for our libraries for the sake of our convenience (numpy --> np and pandas --> pd, tensorlow --> tf).\n",
        "\n",
        "Note: You can import all the libraries that you think will be required or can import it as you go along."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIe16kmoUmhr"
      },
      "source": [
        "import pandas as pd                                     # Data analysis and manipultion tool\n",
        "import numpy as np                                      # Fundamental package for linear algebra and multidimensional arrays\n",
        "import tensorflow as tf                                 # Deep Learning Tool\n",
        "import os                                               # OS module in Python provides a way of using operating system dependent functionality\n",
        "import cv2                                              # Library for image processing\n",
        "from sklearn.model_selection import train_test_split    # For splitting the data into train and validation set\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAXqCpedduVx"
      },
      "source": [
        "## Loading and preparing training data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMXmX8g3dflK"
      },
      "source": [
        "labels = pd.read_csv(\"/content/content/eye_gender_data/Training_set.csv\")   # loading the labels\n",
        "file_paths = [[fname, '/content/content/eye_gender_data/train/' + fname] for fname in labels['filename']]\n",
        "images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
        "train_data = pd.merge(images, labels, how = 'inner', on = 'filename')\n",
        "\n",
        "data = []     # initialize an empty numpy array\n",
        "image_size = 32      # image size taken is 32 here. \n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  \n",
        "  img_array = cv2.imread(train_data['filepaths'][i], cv2.IMREAD_GRAYSCALE)   # converting the image to gray scale\n",
        "  new_img_array = cv2.resize(img_array, (image_size, image_size))      # resizing the image array\n",
        "  data.append(new_img_array) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvIxaRD6sn3m"
      },
      "source": [
        "## Data Pre-processing\n",
        "It is necessary to bring all the images in the same shape and size, also convert them to their pixel values because all machine learning or deep learning models accepts only the numerical data. Also we need to convert all the labels from categorical to numerical values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeRRAYJh2I0i"
      },
      "source": [
        "arr = np.array(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRC8bBYwUvGi",
        "outputId": "005961e8-7183-47ca-fe75-0aaf6b885b17"
      },
      "source": [
        "arr"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[189, 188, 182, ..., 178, 177, 172],\n",
              "        [187, 179, 179, ..., 175, 172, 162],\n",
              "        [185, 181, 184, ..., 168, 157, 149],\n",
              "        ...,\n",
              "        [142, 136, 148, ..., 164, 162, 164],\n",
              "        [140, 150, 161, ..., 169, 164, 164],\n",
              "        [139, 154, 163, ..., 173, 167, 164]],\n",
              "\n",
              "       [[170, 175, 172, ..., 190, 193, 194],\n",
              "        [165, 152, 136, ..., 186, 189, 191],\n",
              "        [147, 124, 107, ..., 183, 189, 193],\n",
              "        ...,\n",
              "        [188, 189, 190, ..., 191, 197, 202],\n",
              "        [187, 190, 190, ..., 195, 197, 196],\n",
              "        [186, 190, 190, ..., 200, 201, 197]],\n",
              "\n",
              "       [[176, 172, 172, ..., 135, 128, 127],\n",
              "        [168, 165, 165, ...,  91, 114, 111],\n",
              "        [164, 165, 162, ...,  76,  62,  68],\n",
              "        ...,\n",
              "        [131, 143, 148, ..., 115, 112, 103],\n",
              "        [131, 145, 150, ..., 113, 108,  99],\n",
              "        [130, 144, 150, ..., 114, 106,  95]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[190, 175, 169, ..., 100, 115, 135],\n",
              "        [177, 161, 147, ...,  83, 103, 101],\n",
              "        [158, 138, 130, ...,  74,  72,  64],\n",
              "        ...,\n",
              "        [144, 137, 134, ..., 150, 151, 148],\n",
              "        [147, 139, 138, ..., 148, 149, 149],\n",
              "        [145, 138, 137, ..., 151, 155, 153]],\n",
              "\n",
              "       [[142, 137, 137, ..., 129, 135, 141],\n",
              "        [141, 142, 128, ..., 107, 117, 126],\n",
              "        [138, 126, 118, ..., 102, 106, 117],\n",
              "        ...,\n",
              "        [157, 147, 143, ..., 154, 153, 171],\n",
              "        [160, 160, 153, ..., 153, 154, 177],\n",
              "        [158, 163, 160, ..., 155, 170, 175]],\n",
              "\n",
              "       [[225, 226, 223, ..., 144, 146, 153],\n",
              "        [223, 224, 223, ..., 146, 144, 130],\n",
              "        [222, 220, 225, ..., 148, 154, 163],\n",
              "        ...,\n",
              "        [205, 195, 194, ..., 223, 219, 221],\n",
              "        [206, 199, 197, ..., 220, 220, 221],\n",
              "        [209, 204, 202, ..., 222, 222, 221]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4puB71FU6xl",
        "outputId": "e69a1447-20df-4ab6-f079-86668cdc88bd"
      },
      "source": [
        "arr.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9220, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SM7bhmwDAG8",
        "outputId": "38e69d9d-5a5d-4b65-aefa-4a22bf0f1ef8"
      },
      "source": [
        "# reshape into 3 channels for feeding into the model\n",
        "train_images_3ch = np.stack([arr]*3, axis=-1)\n",
        "print('\\nTrain_images.shape: {}, of {}'.format(train_images_3ch.shape, train_images_3ch.dtype))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train_images.shape: (9220, 32, 32, 3), of uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxPiZCLpsWrd"
      },
      "source": [
        "# normalisation\n",
        "train_images_scaled = train_images_3ch / 255."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypkgeyllXtDT",
        "outputId": "39496a0a-17f4-4a71-b1c3-16250682a45c"
      },
      "source": [
        "# encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "train_labels = le.fit_transform(train_data[['label']])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxvuOgzqHvAo",
        "outputId": "9a0636f7-0a1e-4712-c89a-500e97f3ca73"
      },
      "source": [
        "train_labels.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9220,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDCZ53yE7340"
      },
      "source": [
        "## Building Model & Hyperparameter tuning\n",
        "Now we are finally ready, and we can train the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOKWYA6Ua4Uh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b19b9b28-9a56-4544-ac86-b98f57e35f14"
      },
      "source": [
        "# Build Cut-VGG19 Model\n",
        "\n",
        "# define input shape\n",
        "INPUT_SHAPE = (32, 32, 3)\n",
        "\n",
        "# get the VGG19 model\n",
        "vgg_layers = tf.keras.applications.vgg19.VGG19(weights='imagenet', include_top=False, \n",
        "                                               input_shape=INPUT_SHAPE) \n",
        "\n",
        "vgg_layers.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"vgg19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "=================================================================\n",
            "Total params: 20,024,384\n",
            "Trainable params: 20,024,384\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQWMyQLva53K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55498f82-7a24-478e-9a18-f3062c943a2f"
      },
      "source": [
        "# Fine-tune all the layers\n",
        "for layer in vgg_layers.layers:\n",
        "    layer.trainable = True \n",
        "\n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_layers.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fbed9af9890> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed91b2e50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed9065d50> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fbed583f410> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed5848310> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed5852210> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fbed583fdd0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed585b4d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed585ea50> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed585b910> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed586d510> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fbed57f4590> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed57ef390> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed586a450> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed583f690> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed57f8410> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fbed586d110> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed5800750> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed58074d0> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed5800690> True\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fbed580f810> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fbed5819890> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jkmDd6PbAJH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8703a804-197d-4bf7-85ed-7e7079406901"
      },
      "source": [
        "# Build CNN model on top of VGG19\n",
        "\n",
        "# define sequential model\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_layers)\n",
        "\n",
        "# add flatten layer\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# add dense layers with some dropout\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(rate=0.3))\n",
        "\n",
        "# add output layer\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) #single node with ‘sigmoid‘ activation to predict the probability for class 1.\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# view model layers\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg19 (Functional)           (None, 1, 1, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 20,221,761\n",
            "Trainable params: 20,221,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHDpTUcwG_e0",
        "outputId": "a0e4a848-383f-4479-cea2-a42f557c139c"
      },
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, \n",
        "                                               restore_best_weights=True,\n",
        "                                               verbose=1)\n",
        "\n",
        "history = model.fit(train_images_scaled, train_labels,\n",
        "                    batch_size=256,\n",
        "                    callbacks=[es_callback], \n",
        "                    validation_split=0.1, epochs=EPOCHS, \n",
        "                    verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "33/33 [==============================] - 1088s 33s/step - loss: 0.5558 - accuracy: 0.7135 - val_loss: 0.3897 - val_accuracy: 0.8308\n",
            "Epoch 2/30\n",
            "33/33 [==============================] - 1072s 32s/step - loss: 0.3501 - accuracy: 0.8539 - val_loss: 0.2842 - val_accuracy: 0.8872\n",
            "Epoch 3/30\n",
            "33/33 [==============================] - 1084s 33s/step - loss: 0.2495 - accuracy: 0.8994 - val_loss: 0.2498 - val_accuracy: 0.8970\n",
            "Epoch 4/30\n",
            "33/33 [==============================] - 1053s 32s/step - loss: 0.2033 - accuracy: 0.9219 - val_loss: 0.2447 - val_accuracy: 0.8948\n",
            "Epoch 5/30\n",
            "33/33 [==============================] - 1075s 33s/step - loss: 0.1706 - accuracy: 0.9359 - val_loss: 0.2280 - val_accuracy: 0.9132\n",
            "Epoch 6/30\n",
            "33/33 [==============================] - 1049s 32s/step - loss: 0.1453 - accuracy: 0.9455 - val_loss: 0.2107 - val_accuracy: 0.9252\n",
            "Epoch 7/30\n",
            "33/33 [==============================] - 1035s 31s/step - loss: 0.1448 - accuracy: 0.9467 - val_loss: 0.1989 - val_accuracy: 0.9219\n",
            "Epoch 8/30\n",
            "33/33 [==============================] - 1055s 32s/step - loss: 0.1067 - accuracy: 0.9642 - val_loss: 0.2036 - val_accuracy: 0.9273\n",
            "Epoch 9/30\n",
            "33/33 [==============================] - 1060s 32s/step - loss: 0.1032 - accuracy: 0.9613 - val_loss: 0.1872 - val_accuracy: 0.9360\n",
            "Epoch 10/30\n",
            "33/33 [==============================] - 1032s 31s/step - loss: 0.1023 - accuracy: 0.9648 - val_loss: 0.2370 - val_accuracy: 0.9262\n",
            "Epoch 11/30\n",
            "33/33 [==============================] - 1034s 31s/step - loss: 0.0825 - accuracy: 0.9712 - val_loss: 0.2010 - val_accuracy: 0.9284\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tc3lSJ2a-OYt"
      },
      "source": [
        "## Validate the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLfoImV7ds57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "93b08bf3-ee4f-44b8-edce-a5875f490b69"
      },
      "source": [
        "# Plot Learning Curves\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "history_df = pd.DataFrame(history.history)\n",
        "history_df[['loss', 'val_loss']].plot(kind='line', ax=ax[0])\n",
        "history_df[['accuracy', 'val_accuracy']].plot(kind='line', ax=ax[1]);"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbpiNvC3r9PK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e7b8f6e-e469-4ddb-99df-4a6084b24360"
      },
      "source": [
        "# saving the model\n",
        "save_dir = \"/results/\"\n",
        "model_name = 'eye_model.h5'\n",
        "model.save(model_name)\n",
        "model_path = save_dir + model_name\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved trained model at /results/eye_model.h5 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLrpm-If-lRT"
      },
      "source": [
        "## Predict The Output For Testing Dataset 😅\n",
        "We have trained our model, evaluated it and now finally we will predict the output/target for the testing data (i.e. Test.csv)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nG70J6Un-s2G"
      },
      "source": [
        "#### Load Test Set\n",
        "Load the test data on which final submission is to be made."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iji8OaFF-fSp"
      },
      "source": [
        "# refer to the instruction on word document\n",
        "test_data = pd.read_csv(\"/content/content/eye_gender_data/Testing_set.csv\" )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndM4OOX_qP3a"
      },
      "source": [
        "file_paths_test = [[fname, '/content/content/eye_gender_data/test/' + fname] for fname in test_data['filename']]\n",
        "images_test = pd.DataFrame(file_paths_test, columns=['filename', 'filepaths'])\n",
        "\n",
        "new_test_data = []\n",
        "#image_size = 32 \n",
        "\n",
        "for i in range(len(images_test)):\n",
        "  \n",
        "  img_array_test = cv2.imread(images_test['filepaths'][i], cv2.IMREAD_GRAYSCALE)   # converting the image to gray scale\n",
        "  new_img_array_test = cv2.resize(img_array_test, (image_size, image_size))      # resizing the image array\n",
        "  new_test_data.append(new_img_array_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqSujaW0CRi9"
      },
      "source": [
        "## Data Pre-processing on test_data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQWUBcCp215g"
      },
      "source": [
        "test_arr = np.array(new_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wy7-NZ7TCiSQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c45ce4a3-c42f-484d-fb0e-9ef45f2b85df"
      },
      "source": [
        "test_arr"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[138, 140, 142, ..., 162, 167, 168],\n",
              "        [140, 134, 137, ..., 159, 162, 161],\n",
              "        [115, 131, 127, ..., 159, 158, 153],\n",
              "        ...,\n",
              "        [151, 164, 171, ..., 171, 159, 157],\n",
              "        [147, 159, 165, ..., 166, 159, 154],\n",
              "        [151, 160, 168, ..., 161, 150, 148]],\n",
              "\n",
              "       [[163, 172, 156, ...,  84,  93,  85],\n",
              "        [148, 158, 144, ...,  77,  75,  69],\n",
              "        [136, 142, 128, ...,  67,  66,  68],\n",
              "        ...,\n",
              "        [114, 109, 108, ..., 129, 134, 144],\n",
              "        [116, 119, 124, ..., 120, 134, 136],\n",
              "        [112, 124, 123, ..., 120, 131, 122]],\n",
              "\n",
              "       [[206, 200, 193, ..., 169, 176, 184],\n",
              "        [205, 203, 186, ..., 171, 175, 180],\n",
              "        [201, 202, 183, ..., 150, 156, 164],\n",
              "        ...,\n",
              "        [216, 218, 215, ..., 211, 214, 218],\n",
              "        [215, 217, 218, ..., 215, 219, 222],\n",
              "        [212, 217, 217, ..., 214, 220, 221]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[146, 149, 151, ..., 139, 142, 143],\n",
              "        [150, 151, 155, ..., 139, 140, 140],\n",
              "        [151, 150, 154, ..., 138, 139, 138],\n",
              "        ...,\n",
              "        [135, 132, 130, ..., 135, 137, 136],\n",
              "        [134, 132, 129, ..., 134, 136, 134],\n",
              "        [136, 134, 131, ..., 133, 136, 134]],\n",
              "\n",
              "       [[186, 184, 186, ..., 193, 194, 198],\n",
              "        [189, 189, 191, ..., 192, 193, 198],\n",
              "        [189, 191, 192, ..., 193, 192, 197],\n",
              "        ...,\n",
              "        [210, 208, 206, ..., 216, 216, 217],\n",
              "        [209, 208, 206, ..., 218, 217, 218],\n",
              "        [210, 207, 205, ..., 216, 219, 219]],\n",
              "\n",
              "       [[226, 224, 222, ..., 184, 175, 169],\n",
              "        [227, 225, 223, ..., 178, 172, 173],\n",
              "        [226, 224, 220, ..., 170, 166, 171],\n",
              "        ...,\n",
              "        [181, 173, 174, ..., 200, 201, 205],\n",
              "        [181, 172, 174, ..., 200, 199, 202],\n",
              "        [183, 177, 174, ..., 200, 198, 201]]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHEGEoz1qpUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec855ec-35ba-4b36-de3d-eaf5de1df150"
      },
      "source": [
        "test_arr.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2305, 32, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KNDswlffvYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6a76378-d036-4c2a-b894-8ddcedffe2c6"
      },
      "source": [
        "# reshape into 3 channels for feeding into the model\n",
        "test_images_3ch = np.stack([test_arr]*3, axis=-1)\n",
        "print('\\nTest_images.shape: {}, of {}'.format(test_images_3ch.shape, test_images_3ch.dtype))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test_images.shape: (2305, 32, 32, 3), of uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIeL1SHdCAcf"
      },
      "source": [
        "# normalisation\n",
        "test_images_scaled = test_images_3ch / 255."
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxtDS6-0J0s2"
      },
      "source": [
        "### Make Prediction on Test Dataset\n",
        "Time to make a submission!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXLCDKVrJuzY"
      },
      "source": [
        "test_predictions = model.predict(test_images_scaled)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMh35Wogw3xn"
      },
      "source": [
        "images_test['predictprobability'] = test_predictions"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqX-PljsxO0O"
      },
      "source": [
        "def convert_to_label (row):\n",
        "  if row['predictprobability'] >=0.5:\n",
        "    return 'male'\n",
        "  else:\n",
        "    return 'female'\n",
        "\n",
        "images_test['predictlabel'] = images_test.apply(convert_to_label, axis=1)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "oUgvbHDq089T",
        "outputId": "45cf0146-b4e4-4792-bcc5-7a73a39c4161"
      },
      "source": [
        "images_test.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepaths</th>\n",
              "      <th>predictprobability</th>\n",
              "      <th>predictlabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Image_1.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_1.jpg</td>\n",
              "      <td>0.998291</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Image_2.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_2.jpg</td>\n",
              "      <td>0.958787</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Image_3.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_3.jpg</td>\n",
              "      <td>0.989709</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Image_4.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_4.jpg</td>\n",
              "      <td>0.985602</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Image_5.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_5.jpg</td>\n",
              "      <td>0.999317</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename  ... predictlabel\n",
              "0  Image_1.jpg  ...         male\n",
              "1  Image_2.jpg  ...         male\n",
              "2  Image_3.jpg  ...         male\n",
              "3  Image_4.jpg  ...         male\n",
              "4  Image_5.jpg  ...         male\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "5aXgvbj-0_Mm",
        "outputId": "99d3a2fa-f34f-4612-bf24-794ef33a255d"
      },
      "source": [
        "images_test.tail()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>filepaths</th>\n",
              "      <th>predictprobability</th>\n",
              "      <th>predictlabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2300</th>\n",
              "      <td>Image_2301.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_23...</td>\n",
              "      <td>0.005048</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2301</th>\n",
              "      <td>Image_2302.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_23...</td>\n",
              "      <td>0.004770</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2302</th>\n",
              "      <td>Image_2303.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_23...</td>\n",
              "      <td>0.999718</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2303</th>\n",
              "      <td>Image_2304.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_23...</td>\n",
              "      <td>0.999712</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2304</th>\n",
              "      <td>Image_2305.jpg</td>\n",
              "      <td>/content/content/eye_gender_data/test/Image_23...</td>\n",
              "      <td>0.943940</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            filename  ... predictlabel\n",
              "2300  Image_2301.jpg  ...       female\n",
              "2301  Image_2302.jpg  ...       female\n",
              "2302  Image_2303.jpg  ...         male\n",
              "2303  Image_2304.jpg  ...         male\n",
              "2304  Image_2305.jpg  ...         male\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QYtTrvdc1JrO",
        "outputId": "f9e821e5-1db7-4ddf-e185-b2f8ea311da4"
      },
      "source": [
        "# How to save prediction results locally via colab notebook?\n",
        "\n",
        "images_test.to_csv(\"submission.csv\", index = False) \n",
        "\n",
        "# To download the csv file locally\n",
        "from google.colab import files        \n",
        "files.download('submission.csv')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_80149cd7-4fd0-4521-9e43-80e755db0884\", \"submission.csv\", 194289)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NohZiMIkO_tX"
      },
      "source": [
        "# **Well Done! 👍**\n",
        "You are all set to make a submission. Let's head to the **[challenge page](https://dphi.tech/challenges/4-week-deep-learning-online-bootcamp-final-assignment-sex-determination-by-morphometry-of-eyes/144/submit)** to make the submission."
      ]
    }
  ]
}